{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80d68cdf-39b5-4d27-970f-ed71e0489faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import fbeta_score,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0830b8de-52b2-479b-b28a-5240a517a8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fd834b4-7870-47af-8e9e-68c37d0a8504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(\n",
    "    X, categorical_features=[], label=None, training=True, encoder=None, lb=None\n",
    "):\n",
    "    \"\"\" Process the data used in the machine learning pipeline.\n",
    "\n",
    "    Processes the data using one hot encoding for the categorical features and a\n",
    "    label binarizer for the labels. This can be used in either training or\n",
    "    inference/validation.\n",
    "\n",
    "    Note: depending on the type of model used, you may want to add in functionality that\n",
    "    scales the continuous data.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    X : pd.DataFrame\n",
    "        Dataframe containing the features and label. Columns in `categorical_features`\n",
    "    categorical_features: list[str]\n",
    "        List containing the names of the categorical features (default=[])\n",
    "    label : str\n",
    "        Name of the label column in `X`. If None, then an empty array will be returned\n",
    "        for y (default=None)\n",
    "    training : bool\n",
    "        Indicator if training mode or inference/validation mode.\n",
    "    encoder : sklearn.preprocessing._encoders.OneHotEncoder\n",
    "        Trained sklearn OneHotEncoder, only used if training=False.\n",
    "    lb : sklearn.preprocessing._label.LabelBinarizer\n",
    "        Trained sklearn LabelBinarizer, only used if training=False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : np.array\n",
    "        Processed data.\n",
    "    y : np.array\n",
    "        Processed labels if labeled=True, otherwise empty np.array.\n",
    "    encoder : sklearn.preprocessing._encoders.OneHotEncoder\n",
    "        Trained OneHotEncoder if training is True, otherwise returns the encoder passed\n",
    "        in.\n",
    "    lb : sklearn.preprocessing._label.LabelBinarizer\n",
    "        Trained LabelBinarizer if training is True, otherwise returns the binarizer\n",
    "        passed in.\n",
    "    \"\"\"\n",
    "\n",
    "    if label is not None:\n",
    "        y = X[label]\n",
    "        X = X.drop([label], axis=1)\n",
    "    else:\n",
    "        y = np.array([])\n",
    "\n",
    "    X_categorical = X[categorical_features].values\n",
    "    X_continuous = X.drop(*[categorical_features], axis=1)\n",
    "\n",
    "    if training is True:\n",
    "        encoder = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "        lb = LabelBinarizer()\n",
    "        X_categorical = encoder.fit_transform(X_categorical)\n",
    "        y = lb.fit_transform(y.values).ravel()\n",
    "    else:\n",
    "        X_categorical = encoder.transform(X_categorical)\n",
    "        try:\n",
    "            y = lb.transform(y.values).ravel()\n",
    "        # Catch the case where y is None because we're doing inference.\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "    X = np.concatenate([X_continuous, X_categorical], axis=1)\n",
    "    return X, y, encoder, lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67564fa2-fc89-434b-bc32-bd799c730415",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data('../data/census.csv')\n",
    "train, test = train_test_split(df, test_size=0.20)\n",
    "cat_features = [\n",
    "    \"workclass\",\n",
    "    \"education\",\n",
    "    \"marital-status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"native-country\",\n",
    "]\n",
    "X_train, y_train, encoder, lb = process_data(train,categorical_features=cat_features, label='salary', training=True, encoder=None, lb=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbe3f5d9-179a-46f6-a913-3c69fc220fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test, _, _ = process_data(\n",
    "    test,\n",
    "    categorical_features=cat_features, \n",
    "    label='salary', \n",
    "    training=False, \n",
    "    encoder=encoder, \n",
    "    lb=lb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87abe089-cf49-4483-bf30-38fa19ae9b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbb0b467-505e-4e2e-b6ca-545aba9a218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Trains a machine learning model and returns it.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    X_train : np.array\n",
    "        Training data.\n",
    "    y_train : np.array\n",
    "        Labels.\n",
    "    Returns\n",
    "    -------\n",
    "    model\n",
    "        Trained machine learning model.\n",
    "    \"\"\"\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100,max_depth=5,criterion=\"gini\",random_state=101)\n",
    "    model = clf.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "model =train_model(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e013fa7a-ff05-44ed-9a84-f1aad9cd4d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=5, random_state=101)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=5, random_state=101)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=5, random_state=101)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a88c3a0b-b4bb-4d28-9c3a-a9fb21aa9dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, X):\n",
    "    \"\"\" Run model inferences and return the predictions.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    model : ???\n",
    "        Trained machine learning model.\n",
    "    X : np.array\n",
    "        Data used for prediction.\n",
    "    Returns\n",
    "    -------\n",
    "    preds : np.array\n",
    "        Predictions from the model.\n",
    "    \"\"\"\n",
    "    predict = model.predict(X)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a440a18d-1c23-4622-80ab-e486f341f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = inference(model,X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f2e09f6-5324-4006-ae9b-246de01b206b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8479776847977685, 0.38676844783715014, 0.5312363477501093)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def compute_model_metrics(y, preds):\n",
    "    \"\"\"\n",
    "    Validates the trained machine learning model using precision, recall, and F1.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    y : np.array\n",
    "        Known labels, binarized.\n",
    "    preds : np.array\n",
    "        Predicted labels, binarized.\n",
    "    Returns\n",
    "    -------\n",
    "    precision : float\n",
    "    recall : float\n",
    "    fbeta : float\n",
    "    \"\"\"\n",
    "    fbeta = fbeta_score(y, preds, beta=1, zero_division=1)\n",
    "    precision = precision_score(y, preds, zero_division=1)\n",
    "    recall = recall_score(y, preds, zero_division=1)\n",
    "    return precision, recall, fbeta\n",
    "\n",
    "compute_model_metrics(y=y_test, preds=predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3568e14d-b6a7-44cf-90eb-57b60bdf0b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61e657ea-4788-44e8-ade3-dd6a6ac25085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to train machine learning model.\n",
    "# Add the necessary imports for the starter code.\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ml.data import process_data\n",
    "from ml.model import train_model \n",
    "\n",
    "# Add code to load in the data.\n",
    "path = '../'\n",
    "data = pd.read_csv('../data/census.csv')\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# Optional enhancement, use K-fold cross validation instead of a train-test split.\n",
    "train, test = train_test_split(data, test_size=0.20)\n",
    "\n",
    "cat_features = [\n",
    "    \"workclass\",\n",
    "    \"education\",\n",
    "    \"marital-status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"native-country\",\n",
    "]\n",
    "\n",
    "# Proces the train data with the process_data function.\n",
    "X_train, y_train, encoder, lb = process_data(\n",
    "    train,\n",
    "    categorical_features=cat_features, \n",
    "    label='salary', \n",
    "    training=True, \n",
    "    encoder=None, \n",
    "    lb=None\n",
    ")\n",
    "\n",
    "# Proces the test data with the process_data function.\n",
    "X_test, y_test, _, _ = process_data(\n",
    "    test,\n",
    "    categorical_features=cat_features, \n",
    "    label='salary', \n",
    "    training=False, \n",
    "    encoder=encoder, \n",
    "    lb=lb\n",
    ")\n",
    "\n",
    "# Train and save a model.\n",
    "model = train_model(X_train,y_train)\n",
    "pd.to_pickle(model, os.path.join(path, \"model.pkl\"))\n",
    "pd.to_pickle(model, os.path.join(path, \"encoder.pkl\"))\n",
    "pd.to_pickle(model, os.path.join(path, \"lb.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0174067e-1b79-4099-8a44-059258bf4af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 101, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed75de66-7d1f-4e4e-8b43-99d383f79e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()=={'bootstrap': True,\n",
    " 'ccp_alpha': 0.0,\n",
    " 'class_weight': None,\n",
    " 'criterion': 'gini',\n",
    " 'max_depth': 5,\n",
    " 'max_features': 'sqrt',\n",
    " 'max_leaf_nodes': None,\n",
    " 'max_samples': None,\n",
    " 'min_impurity_decrease': 0.0,\n",
    " 'min_samples_leaf': 1,\n",
    " 'min_samples_split': 2,\n",
    " 'min_weight_fraction_leaf': 0.0,\n",
    " 'n_estimators': 100,\n",
    " 'n_jobs': None,\n",
    " 'oob_score': False,\n",
    " 'random_state': 101,\n",
    " 'verbose': 0,\n",
    " 'warm_start': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4fcd008-a06a-484d-a8f3-ddeb5838a82d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m process_data\n\u001b[0;32m      8\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/census.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[0;32m     11\u001b[0m train, test \u001b[38;5;241m=\u001b[39m train_test_split(data, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.20\u001b[39m)\n\u001b[0;32m     13\u001b[0m cat_features \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkclass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meducation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnative-country\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     22\u001b[0m ]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ml.model import train_model,inference,compute_model_metrics \n",
    "from ml.data import process_data\n",
    "\n",
    "data = pd.read_csv('../data/census.csv')\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.20)\n",
    "\n",
    "cat_features = [\n",
    "    \"workclass\",\n",
    "    \"education\",\n",
    "    \"marital-status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"native-country\",\n",
    "]\n",
    "\n",
    "X_train, y_train, encoder, lb = process_data(\n",
    "    train,\n",
    "    categorical_features=cat_features, \n",
    "    label='salary', \n",
    "    training=True, \n",
    "    encoder=None, \n",
    "    lb=None\n",
    ")\n",
    "\n",
    "# Proces the test data with the process_data function.\n",
    "X_test, y_test, _, _ = process_data(\n",
    "    test,\n",
    "    categorical_features=cat_features, \n",
    "    label='salary', \n",
    "    training=False, \n",
    "    encoder=encoder, \n",
    "    lb=lb\n",
    ")\n",
    "# Building test functions\n",
    "def test_train_model(X_train,y_train):\n",
    "    '''\n",
    "    \n",
    "    Function to test the train_model function in model.py file\n",
    "    \n",
    "    '''\n",
    "    model = train_model()\n",
    "    assert model.get_params()=={'bootstrap': True,\n",
    "    'ccp_alpha': 0.0,\n",
    "    'class_weight': None,\n",
    "    'criterion': 'gini',\n",
    "    'max_depth': 5,\n",
    "    'max_features': 'sqrt',\n",
    "    'max_leaf_nodes': None,\n",
    "    'max_samples': None,\n",
    "    'min_impurity_decrease': 0.0,\n",
    "    'min_samples_leaf': 1,\n",
    "    'min_samples_split': 2,\n",
    "    'min_weight_fraction_leaf': 0.0,\n",
    "    'n_estimators': 100,\n",
    "    'n_jobs': None,\n",
    "    'oob_score': False,\n",
    "    'random_state': 101,\n",
    "    'verbose': 0,\n",
    "    'warm_start': False}\n",
    "    assert type(model) == RandomForestClassifier\n",
    "\n",
    "def test_inference():\n",
    "    '''\n",
    "    \n",
    "    Function to test the inference function in model.py file\n",
    "\n",
    "    '''\n",
    "    model = train_model(X_train, y_train)\n",
    "    preds = inference(model, X_train)\n",
    "    assert len(preds) == len(X_train) #Assert that the length of the preds and X_train is same\n",
    "    assert np.all((preds==0)|(preds == 1)) == True #To identify cases where the prediction values are not 0 and 1\n",
    "\n",
    "def test_compute_model_metrics():\n",
    "    '''\n",
    "    \n",
    "    Function to test the compute_model_metrics function in model.py file\n",
    "\n",
    "    '''\n",
    "    model = train_model(X_train, y_train)\n",
    "    preds = inference(model, X_test)\n",
    "    metrics = compute_model_metrics(y_test, preds)\n",
    "    assert len(metrics) == 3 #length of metrics\n",
    "    assert type(metrics) == tuple #type of metrics\n",
    "    for metric in metrics:\n",
    "        assert metric >=0 and metric <= 1 #to ensure all metrics values are between 0 and 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_train_model()\n",
    "    test_inference()\n",
    "    test_compute_model_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f9120e-9f0b-4f80-8a3f-576a81b7a4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
